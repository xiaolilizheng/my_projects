{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed06e5bf",
   "metadata": {},
   "source": [
    "## Part 1: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07fef7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/zheng/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/zheng/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "# import gensim\n",
    "import gzip\n",
    "import json\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3a2bbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data into dataframe\n",
    "\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield json.loads(l)\n",
    "\n",
    "def getDF(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "df = getDF('/Users/zheng/Desktop/dataset/Software.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40a3d517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>style</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>03 11, 2014</td>\n",
       "      <td>A240ORQ2LF9LUI</td>\n",
       "      <td>0077613252</td>\n",
       "      <td>{'Format:': ' Loose Leaf'}</td>\n",
       "      <td>Michelle W</td>\n",
       "      <td>The materials arrived early and were in excell...</td>\n",
       "      <td>Material Great</td>\n",
       "      <td>1394496000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>02 23, 2014</td>\n",
       "      <td>A1YCCU0YRLS0FE</td>\n",
       "      <td>0077613252</td>\n",
       "      <td>{'Format:': ' Loose Leaf'}</td>\n",
       "      <td>Rosalind White Ames</td>\n",
       "      <td>I am really enjoying this book with the worksh...</td>\n",
       "      <td>Health</td>\n",
       "      <td>1393113600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>02 17, 2014</td>\n",
       "      <td>A1BJHRQDYVAY2J</td>\n",
       "      <td>0077613252</td>\n",
       "      <td>{'Format:': ' Loose Leaf'}</td>\n",
       "      <td>Allan R. Baker</td>\n",
       "      <td>IF YOU ARE TAKING THIS CLASS DON\"T WASTE YOUR ...</td>\n",
       "      <td>ARE YOU KIDING ME?</td>\n",
       "      <td>1392595200</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>02 17, 2014</td>\n",
       "      <td>APRDVZ6QBIQXT</td>\n",
       "      <td>0077613252</td>\n",
       "      <td>{'Format:': ' Loose Leaf'}</td>\n",
       "      <td>Lucy</td>\n",
       "      <td>This book was missing pages!!! Important pages...</td>\n",
       "      <td>missing pages!!</td>\n",
       "      <td>1392595200</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>10 14, 2013</td>\n",
       "      <td>A2JZTTBSLS1QXV</td>\n",
       "      <td>0077775473</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Albert V.</td>\n",
       "      <td>I have used LearnSmart and can officially say ...</td>\n",
       "      <td>Best study product out there!</td>\n",
       "      <td>1381708800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  verified   reviewTime      reviewerID        asin  \\\n",
       "0      4.0      True  03 11, 2014  A240ORQ2LF9LUI  0077613252   \n",
       "1      4.0      True  02 23, 2014  A1YCCU0YRLS0FE  0077613252   \n",
       "2      1.0      True  02 17, 2014  A1BJHRQDYVAY2J  0077613252   \n",
       "3      3.0      True  02 17, 2014   APRDVZ6QBIQXT  0077613252   \n",
       "4      5.0     False  10 14, 2013  A2JZTTBSLS1QXV  0077775473   \n",
       "\n",
       "                        style         reviewerName  \\\n",
       "0  {'Format:': ' Loose Leaf'}           Michelle W   \n",
       "1  {'Format:': ' Loose Leaf'}  Rosalind White Ames   \n",
       "2  {'Format:': ' Loose Leaf'}       Allan R. Baker   \n",
       "3  {'Format:': ' Loose Leaf'}                 Lucy   \n",
       "4                         NaN            Albert V.   \n",
       "\n",
       "                                          reviewText  \\\n",
       "0  The materials arrived early and were in excell...   \n",
       "1  I am really enjoying this book with the worksh...   \n",
       "2  IF YOU ARE TAKING THIS CLASS DON\"T WASTE YOUR ...   \n",
       "3  This book was missing pages!!! Important pages...   \n",
       "4  I have used LearnSmart and can officially say ...   \n",
       "\n",
       "                         summary  unixReviewTime vote image  \n",
       "0                 Material Great      1394496000  NaN   NaN  \n",
       "1                         Health      1393113600  NaN   NaN  \n",
       "2             ARE YOU KIDING ME?      1392595200    7   NaN  \n",
       "3                missing pages!!      1392595200    3   NaN  \n",
       "4  Best study product out there!      1381708800  NaN   NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31676622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "overall                0\n",
       "verified               0\n",
       "reviewTime             0\n",
       "reviewerID             0\n",
       "asin                   0\n",
       "style             225035\n",
       "reviewerName          24\n",
       "reviewText            66\n",
       "summary               56\n",
       "unixReviewTime         0\n",
       "vote              331583\n",
       "image             457928\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing value\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ed870f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove missing value\n",
    "df.dropna(subset=['reviewText'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa7fbc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4ae595e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the first 20000 data as our training data\n",
    "data = df.loc[:19999, 'reviewText'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db15cee5",
   "metadata": {},
   "source": [
    "## Part 2: Tokenizing and Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd2ac1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We use 183 stop-words from nltk library.\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]\n"
     ]
    }
   ],
   "source": [
    "# use nltk's English stopwords.\n",
    "stopwords = nltk.corpus.stopwords.words('english') #stopwords.append(\"n't\")\n",
    "stopwords.append(\"'s\")\n",
    "stopwords.append(\"'m\")\n",
    "stopwords.append(\"n\") \n",
    "stopwords.append(\"software\")\n",
    "\n",
    "print (\"We use \" + str(len(stopwords)) + \" stop-words from nltk library.\")\n",
    "print (stopwords[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9be42ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "# from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "# tokenization and stemming\n",
    "def tokenization_and_stemming(text):\n",
    "    tokens = []\n",
    "    # exclude stop words and tokenize the document, generate a list of string \n",
    "    for word in nltk.word_tokenize(text):\n",
    "        if word.lower() not in stopwords:\n",
    "            tokens.append(word.lower())\n",
    "\n",
    "    filtered_tokens = []\n",
    "    \n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if token.isalpha():\n",
    "            filtered_tokens.append(token)\n",
    "            \n",
    "    # stemming\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cd4bf03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['materi',\n",
       " 'arriv',\n",
       " 'earli',\n",
       " 'excel',\n",
       " 'condit',\n",
       " 'howev',\n",
       " 'money',\n",
       " 'spent',\n",
       " 'realli',\n",
       " 'come',\n",
       " 'binder',\n",
       " 'loos',\n",
       " 'leaf']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenization_and_stemming(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af4c39cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The materials arrived early and were in excellent condition.  However for the money spent they really should've come with a binder and not just loose leaf.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b0bab9",
   "metadata": {},
   "source": [
    "## Part 3: TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8d973fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['afterward', 'alon', 'alreadi', 'alway', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becom', 'besid', 'cri', 'describ', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'forti', 'henc', 'hereaft', 'herebi', 'howev', 'hundr', 'inde', 'mani', 'meanwhil', 'moreov', 'nobodi', 'noon', 'noth', 'nowher', 'otherwis', 'perhap', 'pleas', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'thenc', 'thereaft', 'therebi', 'therefor', 'togeth', 'twelv', 'twenti', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total, there are 20000 reviews and 823 terms.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# define vectorizer parameters\n",
    "# TfidfVectorizer will help us to create tf-idf matrix\n",
    "# max_df : maximum document frequency for the given word\n",
    "# min_df : minimum document frequency for the given word\n",
    "# max_features: maximum number of words\n",
    "# use_idf: if not true, we only calculate tf\n",
    "# stop_words : built-in stop words\n",
    "# tokenizer: how to tokenize the document\n",
    "# ngram_range: (min_value, max_value), eg. (1, 3) means the result will include 1-gram, 2-gram, 3-gram\n",
    "tfidf_model = TfidfVectorizer(max_df=0.99, max_features=1000,\n",
    "                              min_df=0.01, stop_words='english',\n",
    "                              use_idf=True, tokenizer=tokenization_and_stemming, ngram_range=(1,1))\n",
    "\n",
    "tfidf_matrix = tfidf_model.fit_transform(data) #fit the vectorizer to synopses\n",
    "\n",
    "print (\"In total, there are \" + str(tfidf_matrix.shape[0]) + \\\n",
    "      \" reviews and \" + str(tfidf_matrix.shape[1]) + \" terms.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b25cce4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the words identified by TF-IDF\n",
    "tf_selected_words = tfidf_model.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee90ddd4",
   "metadata": {},
   "source": [
    "## Part 4: K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08772d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-means clustering\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "num_clusters = 4\n",
    "\n",
    "# number of clusters\n",
    "km = KMeans(n_clusters=num_clusters)\n",
    "km.fit(tfidf_matrix)\n",
    "\n",
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d893545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create DataFrame films from all of the input files.\n",
    "product = { 'review': df[:20000].reviewText, 'cluster': clusters}\n",
    "frame = pd.DataFrame(product, columns = ['review', 'cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f015a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The materials arrived early and were in excell...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am really enjoying this book with the worksh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IF YOU ARE TAKING THIS CLASS DON\"T WASTE YOUR ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This book was missing pages!!! Important pages...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have used LearnSmart and can officially say ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Strong backgroung, good read, quite up to date...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>If you live on Mars and never heard of the int...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>i got this book on amazon and it ended up savi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I was very happy with this purchase because th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Recieved in a timely manner- book in great con...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  cluster\n",
       "0  The materials arrived early and were in excell...        0\n",
       "1  I am really enjoying this book with the worksh...        0\n",
       "2  IF YOU ARE TAKING THIS CLASS DON\"T WASTE YOUR ...        0\n",
       "3  This book was missing pages!!! Important pages...        0\n",
       "4  I have used LearnSmart and can officially say ...        0\n",
       "5  Strong backgroung, good read, quite up to date...        0\n",
       "6  If you live on Mars and never heard of the int...        0\n",
       "7  i got this book on amazon and it ended up savi...        0\n",
       "8  I was very happy with this purchase because th...        0\n",
       "9  Recieved in a timely manner- book in great con...        0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0a918d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews included in each cluster:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster\n",
       "0    12156\n",
       "1     4029\n",
       "2     2850\n",
       "3      965"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"Number of reviews included in each cluster:\")\n",
    "frame['cluster'].value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a4892a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Document clustering result by K-means>\n",
      "Cluster 0 words:use,product,program,work,great,good,version,like,time,year,easi,learn,need,money,tri,\n",
      "Cluster 1 words:window,instal,xp,comput,work,run,norton,problem,program,use,os,product,version,upgrad,new,\n",
      "Cluster 2 words:game,play,love,fun,kid,old,great,like,enjoy,nanci,year,realli,son,daughter,learn,\n",
      "Cluster 3 words:offic,microsoft,ms,use,word,version,mac,product,work,suit,need,price,document,excel,instal,\n"
     ]
    }
   ],
   "source": [
    "print (\"<Document clustering result by K-means>\")\n",
    "\n",
    "#km.cluster_centers_ denotes the importances of each items in centroid.\n",
    "#We need to sort it in decreasing-order and get the top k items.\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1] \n",
    "\n",
    "Cluster_keywords_summary = {}\n",
    "for i in range(num_clusters):\n",
    "    print (\"Cluster \" + str(i) + \" words:\", end='')\n",
    "    Cluster_keywords_summary[i] = []\n",
    "    for ind in order_centroids[i, :15]: #replace 15 with n words per cluster\n",
    "        Cluster_keywords_summary[i].append(tf_selected_words[ind])\n",
    "        print (tf_selected_words[ind] + \",\", end='')\n",
    "    print ()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05a609a",
   "metadata": {},
   "source": [
    "## Part 5: Topic Modeling - Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d2ff0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use LDA for clustering\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "lda = LatentDirichletAllocation(n_components=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90aa65aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 4)\n",
      "[[0.07331403 0.06696059 0.79033366 0.06939171]\n",
      " [0.08337635 0.08181271 0.0872994  0.74751153]\n",
      " [0.32904769 0.07440357 0.52510464 0.0714441 ]\n",
      " ...\n",
      " [0.05156374 0.84868997 0.04991719 0.0498291 ]\n",
      " [0.03660801 0.89281158 0.03558806 0.03499235]\n",
      " [0.06137191 0.8130949  0.06461468 0.06091851]]\n"
     ]
    }
   ],
   "source": [
    "# document topic matrix for tfidf_matrix_lda\n",
    "lda_output = lda.fit_transform(tfidf_matrix)\n",
    "print(lda_output.shape)\n",
    "print(lda_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b42cd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 823)\n",
      "[[ 13.41443756  49.12097535  13.81666443 ...   2.22903622 186.65130569\n",
      "   12.96054006]\n",
      " [  9.80149328  63.225375    25.44650645 ... 403.66490176  88.37709587\n",
      "   26.94542099]\n",
      " [ 37.94713146  76.84602521  16.88041174 ...  18.51979822  74.43364108\n",
      "   15.69842163]\n",
      " [  7.37752561  30.52708713  25.9790145  ...   0.78124723 159.55457001\n",
      "    8.67242563]]\n"
     ]
    }
   ],
   "source": [
    "# topics and words matrix\n",
    "topic_word = lda.components_\n",
    "print(topic_word.shape)\n",
    "print(topic_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b49d2a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic0</th>\n",
       "      <th>Topic1</th>\n",
       "      <th>Topic2</th>\n",
       "      <th>Topic3</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Doc0</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.07</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc1</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc2</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.07</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc3</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.07</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc4</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc5</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.07</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc6</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc7</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.07</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc8</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc9</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Topic0  Topic1  Topic2  Topic3  topic\n",
       "Doc0    0.07    0.07    0.79    0.07      2\n",
       "Doc1    0.08    0.08    0.09    0.75      3\n",
       "Doc2    0.33    0.07    0.53    0.07      2\n",
       "Doc3    0.08    0.07    0.78    0.07      2\n",
       "Doc4    0.19    0.05    0.70    0.05      2\n",
       "Doc5    0.07    0.07    0.80    0.07      2\n",
       "Doc6    0.08    0.44    0.39    0.08      1\n",
       "Doc7    0.33    0.06    0.54    0.07      2\n",
       "Doc8    0.73    0.09    0.09    0.09      0\n",
       "Doc9    0.08    0.07    0.77    0.08      2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# column names\n",
    "topic_names = [\"Topic\" + str(i) for i in range(lda.n_components)]\n",
    "\n",
    "# index names\n",
    "doc_names = [\"Doc\" + str(i) for i in range(len(data))]\n",
    "\n",
    "df_document_topic = pd.DataFrame(np.round(lda_output, 2), columns=topic_names, index=doc_names)\n",
    "\n",
    "# get dominant topic for each document\n",
    "topic = np.argmax(df_document_topic.values, axis=1)\n",
    "df_document_topic['topic'] = topic\n",
    "\n",
    "df_document_topic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a75c756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic\n",
       "1   6118\n",
       "2   6001\n",
       "0   4145\n",
       "3   3736"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_document_topic['topic'].value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "657bf582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 13.41443756  49.12097535  13.81666443 ...   2.22903622 186.65130569\n",
      "   12.96054006]\n",
      " [  9.80149328  63.225375    25.44650645 ... 403.66490176  88.37709587\n",
      "   26.94542099]\n",
      " [ 37.94713146  76.84602521  16.88041174 ...  18.51979822  74.43364108\n",
      "   15.69842163]\n",
      " [  7.37752561  30.52708713  25.9790145  ...   0.78124723 159.55457001\n",
      "    8.67242563]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abil</th>\n",
       "      <th>abl</th>\n",
       "      <th>absolut</th>\n",
       "      <th>accept</th>\n",
       "      <th>access</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>activ</th>\n",
       "      <th>actual</th>\n",
       "      <th>ad</th>\n",
       "      <th>...</th>\n",
       "      <th>wors</th>\n",
       "      <th>worst</th>\n",
       "      <th>worth</th>\n",
       "      <th>write</th>\n",
       "      <th>written</th>\n",
       "      <th>wrong</th>\n",
       "      <th>x</th>\n",
       "      <th>xp</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic0</th>\n",
       "      <td>13.414438</td>\n",
       "      <td>49.120975</td>\n",
       "      <td>13.816664</td>\n",
       "      <td>18.391069</td>\n",
       "      <td>18.913425</td>\n",
       "      <td>113.014818</td>\n",
       "      <td>11.006753</td>\n",
       "      <td>78.394654</td>\n",
       "      <td>25.472139</td>\n",
       "      <td>26.023344</td>\n",
       "      <td>...</td>\n",
       "      <td>18.387131</td>\n",
       "      <td>26.059047</td>\n",
       "      <td>41.971626</td>\n",
       "      <td>12.911204</td>\n",
       "      <td>8.837372</td>\n",
       "      <td>30.297878</td>\n",
       "      <td>0.279184</td>\n",
       "      <td>2.229036</td>\n",
       "      <td>186.651306</td>\n",
       "      <td>12.960540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic1</th>\n",
       "      <td>9.801493</td>\n",
       "      <td>63.225375</td>\n",
       "      <td>25.446506</td>\n",
       "      <td>11.679278</td>\n",
       "      <td>53.933266</td>\n",
       "      <td>11.016197</td>\n",
       "      <td>65.288977</td>\n",
       "      <td>35.453149</td>\n",
       "      <td>46.191911</td>\n",
       "      <td>33.402185</td>\n",
       "      <td>...</td>\n",
       "      <td>24.641164</td>\n",
       "      <td>29.327180</td>\n",
       "      <td>47.002538</td>\n",
       "      <td>22.555755</td>\n",
       "      <td>15.740390</td>\n",
       "      <td>33.956513</td>\n",
       "      <td>69.966436</td>\n",
       "      <td>403.664902</td>\n",
       "      <td>88.377096</td>\n",
       "      <td>26.945421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic2</th>\n",
       "      <td>37.947131</td>\n",
       "      <td>76.846025</td>\n",
       "      <td>16.880412</td>\n",
       "      <td>5.721158</td>\n",
       "      <td>40.775366</td>\n",
       "      <td>3.195640</td>\n",
       "      <td>1.051999</td>\n",
       "      <td>4.769690</td>\n",
       "      <td>50.301633</td>\n",
       "      <td>33.772845</td>\n",
       "      <td>...</td>\n",
       "      <td>4.180134</td>\n",
       "      <td>4.160612</td>\n",
       "      <td>64.928701</td>\n",
       "      <td>75.796930</td>\n",
       "      <td>27.843203</td>\n",
       "      <td>17.068288</td>\n",
       "      <td>15.174214</td>\n",
       "      <td>18.519798</td>\n",
       "      <td>74.433641</td>\n",
       "      <td>15.698422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic3</th>\n",
       "      <td>7.377526</td>\n",
       "      <td>30.527087</td>\n",
       "      <td>25.979015</td>\n",
       "      <td>0.602154</td>\n",
       "      <td>0.477439</td>\n",
       "      <td>0.253825</td>\n",
       "      <td>3.921913</td>\n",
       "      <td>42.247571</td>\n",
       "      <td>33.354503</td>\n",
       "      <td>5.793535</td>\n",
       "      <td>...</td>\n",
       "      <td>0.908189</td>\n",
       "      <td>3.720994</td>\n",
       "      <td>27.706233</td>\n",
       "      <td>8.080571</td>\n",
       "      <td>2.268055</td>\n",
       "      <td>10.937177</td>\n",
       "      <td>0.256767</td>\n",
       "      <td>0.781247</td>\n",
       "      <td>159.554570</td>\n",
       "      <td>8.672426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 823 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             abil        abl    absolut     accept     access     account  \\\n",
       "Topic0  13.414438  49.120975  13.816664  18.391069  18.913425  113.014818   \n",
       "Topic1   9.801493  63.225375  25.446506  11.679278  53.933266   11.016197   \n",
       "Topic2  37.947131  76.846025  16.880412   5.721158  40.775366    3.195640   \n",
       "Topic3   7.377526  30.527087  25.979015   0.602154   0.477439    0.253825   \n",
       "\n",
       "              act      activ     actual         ad  ...       wors      worst  \\\n",
       "Topic0  11.006753  78.394654  25.472139  26.023344  ...  18.387131  26.059047   \n",
       "Topic1  65.288977  35.453149  46.191911  33.402185  ...  24.641164  29.327180   \n",
       "Topic2   1.051999   4.769690  50.301633  33.772845  ...   4.180134   4.160612   \n",
       "Topic3   3.921913  42.247571  33.354503   5.793535  ...   0.908189   3.720994   \n",
       "\n",
       "            worth      write    written      wrong          x          xp  \\\n",
       "Topic0  41.971626  12.911204   8.837372  30.297878   0.279184    2.229036   \n",
       "Topic1  47.002538  22.555755  15.740390  33.956513  69.966436  403.664902   \n",
       "Topic2  64.928701  75.796930  27.843203  17.068288  15.174214   18.519798   \n",
       "Topic3  27.706233   8.080571   2.268055  10.937177   0.256767    0.781247   \n",
       "\n",
       "              year        yes  \n",
       "Topic0  186.651306  12.960540  \n",
       "Topic1   88.377096  26.945421  \n",
       "Topic2   74.433641  15.698422  \n",
       "Topic3  159.554570   8.672426  \n",
       "\n",
       "[4 rows x 823 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# topic word matrix\n",
    "print(lda.components_)\n",
    "# topic-word matrix\n",
    "df_topic_words = pd.DataFrame(lda.components_)\n",
    "\n",
    "# column and index\n",
    "df_topic_words.columns = tfidf_model.get_feature_names_out()\n",
    "df_topic_words.index = topic_names\n",
    "\n",
    "df_topic_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e576fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 0</th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>Word 3</th>\n",
       "      <th>Word 4</th>\n",
       "      <th>Word 5</th>\n",
       "      <th>Word 6</th>\n",
       "      <th>Word 7</th>\n",
       "      <th>Word 8</th>\n",
       "      <th>Word 9</th>\n",
       "      <th>Word 10</th>\n",
       "      <th>Word 11</th>\n",
       "      <th>Word 12</th>\n",
       "      <th>Word 13</th>\n",
       "      <th>Word 14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic 0</th>\n",
       "      <td>product</td>\n",
       "      <td>quicken</td>\n",
       "      <td>use</td>\n",
       "      <td>money</td>\n",
       "      <td>year</td>\n",
       "      <td>tax</td>\n",
       "      <td>support</td>\n",
       "      <td>map</td>\n",
       "      <td>version</td>\n",
       "      <td>work</td>\n",
       "      <td>intuit</td>\n",
       "      <td>turbotax</td>\n",
       "      <td>program</td>\n",
       "      <td>return</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 1</th>\n",
       "      <td>window</td>\n",
       "      <td>instal</td>\n",
       "      <td>work</td>\n",
       "      <td>xp</td>\n",
       "      <td>comput</td>\n",
       "      <td>run</td>\n",
       "      <td>problem</td>\n",
       "      <td>use</td>\n",
       "      <td>program</td>\n",
       "      <td>norton</td>\n",
       "      <td>product</td>\n",
       "      <td>version</td>\n",
       "      <td>os</td>\n",
       "      <td>upgrad</td>\n",
       "      <td>drive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 2</th>\n",
       "      <td>use</td>\n",
       "      <td>program</td>\n",
       "      <td>offic</td>\n",
       "      <td>great</td>\n",
       "      <td>product</td>\n",
       "      <td>good</td>\n",
       "      <td>easi</td>\n",
       "      <td>word</td>\n",
       "      <td>work</td>\n",
       "      <td>learn</td>\n",
       "      <td>need</td>\n",
       "      <td>price</td>\n",
       "      <td>version</td>\n",
       "      <td>like</td>\n",
       "      <td>excel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 3</th>\n",
       "      <td>game</td>\n",
       "      <td>play</td>\n",
       "      <td>love</td>\n",
       "      <td>fun</td>\n",
       "      <td>kid</td>\n",
       "      <td>old</td>\n",
       "      <td>great</td>\n",
       "      <td>learn</td>\n",
       "      <td>enjoy</td>\n",
       "      <td>son</td>\n",
       "      <td>year</td>\n",
       "      <td>like</td>\n",
       "      <td>daughter</td>\n",
       "      <td>realli</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word 0   Word 1 Word 2 Word 3   Word 4 Word 5   Word 6 Word 7  \\\n",
       "Topic 0  product  quicken    use  money     year    tax  support    map   \n",
       "Topic 1   window   instal   work     xp   comput    run  problem    use   \n",
       "Topic 2      use  program  offic  great  product   good     easi   word   \n",
       "Topic 3     game     play   love    fun      kid    old    great  learn   \n",
       "\n",
       "          Word 8  Word 9  Word 10   Word 11   Word 12 Word 13 Word 14  \n",
       "Topic 0  version    work   intuit  turbotax   program  return    time  \n",
       "Topic 1  program  norton  product   version        os  upgrad   drive  \n",
       "Topic 2     work   learn     need     price   version    like   excel  \n",
       "Topic 3    enjoy     son     year      like  daughter  realli    time  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print top n keywords for each topic\n",
    "def print_topic_words(tfidf_model, lda_model, n_words):\n",
    "    words = np.array(tfidf_model.get_feature_names_out())\n",
    "    topic_words = []\n",
    "    # for each topic, we have words weight\n",
    "    for topic_words_weights in lda_model.components_:\n",
    "        top_words = topic_words_weights.argsort()[::-1][:n_words]\n",
    "        topic_words.append(words.take(top_words))\n",
    "    return topic_words\n",
    "\n",
    "topic_keywords = print_topic_words(tfidf_model=tfidf_model, lda_model=lda, n_words=15)        \n",
    "\n",
    "df_topic_words = pd.DataFrame(topic_keywords)\n",
    "df_topic_words.columns = ['Word '+str(i) for i in range(df_topic_words.shape[1])]\n",
    "df_topic_words.index = ['Topic '+str(i) for i in range(df_topic_words.shape[0])]\n",
    "df_topic_words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
